{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 从极大似然估计到机器学习\n",
    "——以一元线性回归任务为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 最大似然估计最吸引人的地方在于，它被证明当样本数目m趋近于无穷时，就收敛率而言是最好的渐近估计。\n",
    "\n",
    "> ——《deep learning book》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求极大似然函数估计值的一般步骤：\n",
    "（1） 写出似然函数；\n",
    "（2） 对似然函数取对数，并整理；\n",
    "（3） 求导数 ；\n",
    "（4） 解似然方程 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元线性回归的公式可以表示为$y=kx+b+\\varepsilon$\n",
    "\n",
    "其中，x是自变量，y是因变量，k是斜率，b是常数项，$\\varepsilon$是随机误差，极大似然法认为随机误差$\\varepsilon$服从$N(0,\\sigma^2)$的正态分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即$$p(\\varepsilon)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{\\varepsilon^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 写出似然函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L=\\prod\\limits_{i=1}^{n}p({\\varepsilon_i})\n",
    "=\\prod\\limits_{i=1}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^-{\\frac{\\varepsilon_i^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)对似然函数取对数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$log(L)=\\sum\\limits_{i=1}^n[-log(\\sqrt{2\\pi}\\sigma)-{\\frac{\\varepsilon_i^2}{2\\sigma^2}}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "又因为$\\varepsilon_i=y_i-kx_i-b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$log(L)=\\sum\\limits_{i=1}^n[-log(\\sqrt{2\\pi}\\sigma)-{\\frac{(y_i-kx_i-b)^2}{2\\sigma^2}}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要最大化极大似然函数，只需要极小化$(y_i-kx_i-b)^2$，因为其他的量都是常量\n",
    "！注：这里是和最小二乘法的目标是一致的，不过要注意，仅仅在这个特例下一致，在有些时候，极大似然估计和最小二乘估计并不是一致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以往的思路中是通过求导解似然方程的方式，分别对k，b求偏导，令导数为0，即可求出极值，即\n",
    "\n",
    "$$\\hat k=\\frac{\\sum\\limits_{i=1}^n(x_i-\\bar x)(y_i-\\bar y)}{\\sum\\limits_{i=1}^n(x_i-\\bar x)^2}$$\n",
    "\n",
    "$$\\hat b=\\bar y-\\hat k\\bar x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习中的一元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在神经网络机器学习，则是通过另一种方式求得：通过人工指定一个$k_0$和$b_0$，通过梯度下降的方式，求得似然函数的极值（梯度下降只能求得函数的极小值，求似然函数的极大值是通过求$\\sum\\limits(y_i-kx_i-b)$的极小值实现的）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降-神经网络的基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络通过人工指定一个$k_0$和$b_0$，然后求取$\\sum\\limits(y_i-kx_i-b)$关于k，b在此时的导数，以一定的学习速率$\\theta$沿梯度下降，从而最小化$\\sum\\limits(y_i-kx_i-b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一元线性回归模型中，一个特别好的性质是$\\sum\\limits(y_i-kx_i-b)$关于k，b的函数是凸函数，通过调整合适的学习速率，我们就一定可以得到十分接近估计值的k和b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个一元线性回归的实例\n",
    "用回归模型预测木材剩余物"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伊春林区位于黑龙江省东北部。全区有森林面积218.9732万公顷，木材蓄积量为2.324602亿m3。森林覆盖率为62.5%，是我国主要的木材工业基地之一。1999年伊春林区木材采伐量为532万m3。按此速度44年之后，1999年的蓄积量将被采伐一空。所以目前亟待调整木材采伐规划与方式，保护森林生态环境。为缓解森林资源危机，并解决部分职工就业问题，除了做好木材的深加工外，还要充分利用木材剩余物生产林业产品，如纸浆、纸袋、纸板等。因此预测林区的年木材剩余物是安排木材剩余物加工生产的一个关键环节。下面，利用一元线性回归模型预测林区每年的木材剩余物。显然引起木材剩余物变化的关键因素是年木材采伐量。\n",
    "\n",
    "给出伊春林区16个林业局1999年木材剩余物和年木材采伐量数据如下。观测点近似服从线性关系。建立一元线性回归模型"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "年木材采伐量数据\n",
    "林业局名\t年木材剩余物yt（万m3）\t年木材采伐量xt（万m3）\n",
    "乌伊岭\t26.13\t61.4\n",
    "东风\t23.49\t48.3\n",
    "新青\t21.97\t51.8\n",
    "红星\t11.53\t35.9\n",
    "五营\t7.18\t17.8\n",
    "上甘岭\t6.80\t17.0\n",
    "友好\t18.43\t55.0\n",
    "翠峦\t11.69\t32.7\n",
    "乌马河\t6.80\t17.0\n",
    "美溪\t9.69\t27.3\n",
    "大丰\t7.99\t21.5\n",
    "南岔\t12.15\t35.5\n",
    "带岭\t6.80\t17.0\n",
    "朗乡\t17.20\t50.0\n",
    "桃山\t9.50\t30.0\n",
    "双丰\t5.52\t13.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的直观展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ba19876860>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经典OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=16\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   146.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>8.30e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:57:55</td>     <th>  Log-Likelihood:    </th> <td> -33.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    16</td>      <th>  AIC:               </th> <td>   70.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    14</td>      <th>  BIC:               </th> <td>   71.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.7629</td> <td>    1.221</td> <td>   -0.625</td> <td> 0.542</td> <td>   -3.382</td> <td>    1.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4043</td> <td>    0.033</td> <td>   12.113</td> <td> 0.000</td> <td>    0.333</td> <td>    0.476</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.117</td> <th>  Durbin-Watson:     </th> <td>   1.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.347</td> <th>  Jarque-Bera (JB):  </th> <td>   0.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.554</td> <th>  Prob(JB):          </th> <td>   0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.235</td> <th>  Cond. No.          </th> <td>    87.8</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.913\n",
       "Model:                            OLS   Adj. R-squared:                  0.907\n",
       "Method:                 Least Squares   F-statistic:                     146.7\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):           8.30e-09\n",
       "Time:                        09:57:55   Log-Likelihood:                -33.013\n",
       "No. Observations:                  16   AIC:                             70.03\n",
       "Df Residuals:                      14   BIC:                             71.57\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.7629      1.221     -0.625      0.542      -3.382       1.856\n",
       "x1             0.4043      0.033     12.113      0.000       0.333       0.476\n",
       "==============================================================================\n",
       "Omnibus:                        2.117   Durbin-Watson:                   1.482\n",
       "Prob(Omnibus):                  0.347   Jarque-Bera (JB):                0.856\n",
       "Skew:                           0.554   Prob(JB):                        0.652\n",
       "Kurtosis:                       3.235   Cond. No.                         87.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "\n",
    "x_ = sm.add_constant(x)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = x_).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习方法1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先通过完全手写的方式，来实现一次最简单的神经网络，注意，这个神经网络只有两个需要学习的参数k、b，我们将通过手动求导的方式，进行反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 None\n",
      "0.3981405880791939 -0.5350721488407616 58.21208419551689\n",
      "0.4040726517595454 -0.755240093404616 58.052496404042685\n",
      "0.4042728033288974 -0.7626686986927596 58.052314724488774\n",
      "0.40427955656906356 -0.762919344519683 58.052314517659305\n",
      "0.4042797844276454 -0.7629278014679431 58.052314517423824\n",
      "0.4042797921157376 -0.7629280868107092 58.05231451742352\n",
      "0.4042797923751388 -0.7629280964383559 58.05231451742356\n",
      "0.4042797923838911 -0.7629280967631988 58.05231451742355\n",
      "0.4042797923841864 -0.7629280967741576 58.05231451742356\n"
     ]
    }
   ],
   "source": [
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "\n",
    "k,b = 0,0\n",
    "error=None\n",
    "def Derivative(k,b):\n",
    "    dk = sum([-2*xi*(yi-k*xi-b) for xi,yi in zip(x,y)])\n",
    "    db = sum([-2*(yi-k*xi-b) for xi,yi in zip(x,y)])\n",
    "    error = sum([(yi-k*xi-b)**2 for xi,yi in zip(x,y)])\n",
    "    return k-0.00001*dk,b-0.01*db,error\n",
    "for i in range(1000):\n",
    "    if i%100==0:\n",
    "        print(k,b,error)\n",
    "    k,b,error = Derivative(k,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习方法2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们尝试使用tensorflow神经网络框架实现同样的神经网络结构，并使用框架自带的反向传播优化器进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.]], dtype=float32), array([[0.]], dtype=float32), 3238.6912]\n",
      "[array([[0.37504187]], dtype=float32), array([[0.3519281]], dtype=float32), 61.56008]\n",
      "[array([[0.37805682]], dtype=float32), array([[0.28696278]], dtype=float32), 61.1187]\n",
      "[array([[0.38077748]], dtype=float32), array([[0.1780673]], dtype=float32), 60.51558]\n",
      "[array([[0.38472852]], dtype=float32), array([[0.01992275]], dtype=float32), 59.7572]\n",
      "[array([[0.3898208]], dtype=float32), array([[-0.1839131]], dtype=float32), 58.98495]\n",
      "[array([[0.39541033]], dtype=float32), array([[-0.40770826]], dtype=float32), 58.403343]\n",
      "[array([[0.40026125]], dtype=float32), array([[-0.601971]], dtype=float32), 58.124374]\n",
      "[array([[0.40318114]], dtype=float32), array([[-0.7189207]], dtype=float32), 58.057724]\n",
      "[array([[0.4041519]], dtype=float32), array([[-0.757804]], dtype=float32), 58.05238]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "x = np.array(x).reshape([-1,1])\n",
    "y = np.array(y).reshape([-1,1])\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32,shape=[None,1])\n",
    "y_placeholder = tf.placeholder(tf.float32,shape=[None,1])\n",
    "#################################\n",
    "W = tf.Variable(tf.zeros([1,1]))\n",
    "b = tf.Variable(tf.zeros([1,1]))\n",
    "y_p = tf.matmul(x_placeholder,W)+b\n",
    "#################################\n",
    "loss = tf.reduce_sum((y_p-y_placeholder)**2)\n",
    "train = tf.train.AdamOptimizer().minimize(loss) # 框架会自动进行求导，反向传播，并进行参数优化\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        if i%1000==0:\n",
    "            _ = sess.run([W,b,loss],feed_dict={x_placeholder:x,y_placeholder:y})\n",
    "            print(_)\n",
    "        sess.run(train,feed_dict={x_placeholder:x,y_placeholder:y})\n",
    "# 重设默认图\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.37409627]], dtype=float32), array([1.2152207], dtype=float32)]\n",
      "[array([[0.40040913]], dtype=float32), array([-0.6072346], dtype=float32)]\n",
      "[array([[0.4042797]], dtype=float32), array([-0.76292455], dtype=float32)]\n",
      "[array([[0.4042794]], dtype=float32), array([-0.7629279], dtype=float32)]\n",
      "[array([[0.4042798]], dtype=float32), array([-0.76292783], dtype=float32)]\n",
      "[array([[0.4042798]], dtype=float32), array([-0.7629279], dtype=float32)]\n",
      "[array([[0.4042797]], dtype=float32), array([-0.762928], dtype=float32)]\n",
      "[array([[0.40427977]], dtype=float32), array([-0.76292783], dtype=float32)]\n",
      "[array([[0.4042798]], dtype=float32), array([-0.7629277], dtype=float32)]\n",
      "[array([[0.40427977]], dtype=float32), array([-0.76292783], dtype=float32)]\n",
      "[<tf.Variable 'net/layer/weights:0' shape=(1, 1) dtype=float32_ref>, <tf.Variable 'net/layer/biases:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# variable scope 和slim的使用\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "x = np.array(x).reshape([-1,1])\n",
    "y = np.array(y).reshape([-1,1])\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32,shape=[None,1])\n",
    "y_placeholder = tf.placeholder(tf.float32,shape=[None,1])\n",
    "###############################\n",
    "with tf.variable_scope('net'):\n",
    "    y_p=slim.fully_connected(x_placeholder,1,\n",
    "                             weights_initializer=tf.random_normal_initializer,\n",
    "                             biases_initializer=tf.random_normal_initializer,\n",
    "                             scope='layer')\n",
    "###############################\n",
    "loss = tf.reduce_sum((y_p-y_placeholder)**2)\n",
    "train = tf.train.AdamOptimizer().minimize(loss,var_list=tf.get_collection('trainable_variables',scope='net'))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(30000):\n",
    "        if i%3000==0:\n",
    "            _ = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='net'),feed_dict={x_placeholder:x,y_placeholder:y})\n",
    "            print(_)\n",
    "#             _ = sess.run(loss,feed_dict={x_placeholder:x,y_placeholder:y})\n",
    "#             print(_)\n",
    "        sess.run(train,feed_dict={x_placeholder:x,y_placeholder:y})\n",
    "print(tf.get_collection('trainable_variables',scope='net'))\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow2.0 推荐的新方式\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = [61.4,48.3,51.8,35.9,17.8,17.0,55,32.7,17.0,27.3,21.5,35.5,17.0,50.0,30.0,13.8]\n",
    "y = [26.13,23.49,21.97,11.53,7.18,6.80,18.43,11.69,6.80,9.69,7.99,12.15,6.80,17.20,9.50,5.52]\n",
    "x = np.array(x).reshape([-1,1])\n",
    "y = np.array(y).reshape([-1,1])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(1, activation=None)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "\n",
    "model.fit(x, y, epochs=10000,verbose=0)\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.40427712]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([-0.76282233], dtype=float32)>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
