{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax回归介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道MNIST 数据集的每一张图片都表示一个(0 到9 的) 数字．那么，如果模\n",
    "型若能看到一张图就能知道它属于各个数字的对应概率就好了。比如，我们的模型可能\n",
    "看到一张数字\"9\" 的图片，就判断出它是数字\"9\" 的概率为80%，而有5% 的概率属于数\n",
    "字\"8\"（因为8 和9 都有上半部分的小圆），同时给予其他数字对应的小概率（因为该图\n",
    "像代表它们的可能性微乎其微）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是能够体现softmax 回归自然简约的一个典型案例．softmax 模型可以用来给\n",
    "不同的对象分配概率．在后文，我们训练更加复杂的模型时，最后一步也往往需要用\n",
    "softmax 来分配概率．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鸢尾花数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面已经简单介绍过了鸢尾花数据集，这一节让我们用softmax分类器来试试将它们分类！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_iris()['data']\n",
    "target = sklearn.datasets.load_iris()['target']\n",
    "\n",
    "columns = sklearn.datasets.load_iris()['feature_names']\n",
    "target_names = sklearn.datasets.load_iris()['target_names']\n",
    "iris =    pd.concat([pd.DataFrame(data,columns=columns),\n",
    "          pd.DataFrame([[i,target_names[i]] for i in target],columns=['target','target_label'])],\n",
    "          axis=1)\n",
    "#虚拟变量的one_hot编码\n",
    "iris = pd.get_dummies(iris,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)']].values,iris[['target_0', 'target_1', 'target_2']].values,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"network/fully_connected/BiasAdd:0\", shape=(?, 3), dtype=float32)\n",
      "5.0953555 4.7522497 0.35555556\n",
      "0.969433 1.0228369 0.5555556\n",
      "0.59505606 0.62680805 0.62222224\n",
      "0.43157244 0.44442746 0.8666667\n",
      "0.31595135 0.31595886 1.0\n",
      "0.23368332 0.22667868 1.0\n",
      "0.1772938 0.16663915 1.0\n",
      "0.13897245 0.12604564 1.0\n",
      "0.11277349 0.098031655 1.0\n",
      "0.09467914 0.078323245 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x_placeholder = tf.placeholder(tf.float32,shape=[None,4])\n",
    "y_placeholder = tf.placeholder(tf.float32,shape=[None,3])\n",
    "with tf.variable_scope('network'):\n",
    "    logits = slim.fully_connected(x_placeholder,3,\n",
    "                                  biases_initializer=tf.random_normal_initializer,\n",
    "                                  weights_initializer=tf.random_normal_initializer,\n",
    "                                  activation_fn=None)\n",
    "    y_predict = tf.nn.softmax(logits)\n",
    "print(logits)\n",
    "loss = slim.losses.softmax_cross_entropy(logits,y_placeholder)\n",
    "train = slim.train.AdamOptimizer().minimize(loss,var_list=tf.get_collection('trainable_variables',scope='network'))\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_placeholder,1))\n",
    "correct_prediction = tf.cast(correct_prediction,'float32')\n",
    "accurrency = tf.reduce_mean(correct_prediction)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        if i%1000 ==0:\n",
    "            _loss_train = sess.run(loss,feed_dict={x_placeholder:x_train,y_placeholder:y_train})\n",
    "            _loss_test,_accurrency = sess.run([loss,accurrency],feed_dict={x_placeholder:x_test,y_placeholder:y_test})\n",
    "            print(_loss_train,_loss_test,_accurrency)\n",
    "        sess.run(train,feed_dict={x_placeholder:x_train,y_placeholder:y_train})\n",
    "    # 查看各个变量的权重\n",
    "    w = sess.run(tf.get_collection('trainable_variables',scope='network'),\n",
    "            feed_dict={x_placeholder:x_test,y_placeholder:y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainable_variables'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.GraphKeys.TRAINABLE_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST手写数据集识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST是一份手写数据集，数据集可被分为三部分：55000 行训练用点数据集（mnist.train），10000行测试数据集(mnist.test)，以及5000 行验证数据集（mnist.validation）．这样的切分很重要：在机器学习模型设计时必须有一个单独的测试数据集不用于训练而是用来评估这个模型的性能，从而更加容易把设计的模型推广到其他数据集上（泛化）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过tensorflow.example.tutorials.mnist轻松的加载它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 这里one_hot的含义是one hot编码，即用n个单元对n个状态编码，\n",
    "# 以mnist数据集为例，0,1,2,3,4,5,6,7,8,9这10种数字将分别被编码为：\n",
    "# 0 = [1,0,0,0,0,0,0,0,0,0]\n",
    "# 1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "# ...\n",
    "# 9 = [0,0,0,0,0,0,0,0,0,1]\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist 数据集中的每一张图片被存储成了一个784维的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09803922, 0.29803923, 0.29803923, 0.29803923,\n",
       "        0.28235295, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333334, 0.8705883 , 0.8705883 , 0.8705883 , 0.909804  ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9843138 , 0.8705883 ,\n",
       "        0.8705883 , 0.8705883 , 0.8705883 , 0.8705883 , 0.8705883 ,\n",
       "        0.47450984, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.42352945,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.86274517, 0.9921569 , 0.9921569 , 0.80392164,\n",
       "        0.6745098 , 0.6745098 , 0.6745098 , 0.6745098 , 0.6745098 ,\n",
       "        0.49803925, 0.34117648, 0.25490198, 0.32941177, 0.91372555,\n",
       "        0.9921569 , 0.9921569 , 0.45882356, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1254902 ,\n",
       "        0.34901962, 0.3372549 , 0.04313726, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
       "        0.2627451 , 0.7725491 , 0.9921569 , 0.9921569 , 0.6745098 ,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1764706 , 0.28627452, 0.75294125, 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.76470596, 0.12156864, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5529412 , 0.76470596, 0.76470596, 0.76470596,\n",
       "        0.76470596, 0.76470596, 0.76470596, 0.97647065, 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.6666667 , 0.23137257, 0.01176471,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.72156864,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.83921576, 0.4901961 , 0.44705886, 0.06666667, 0.01176471,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38823533, 0.87843144, 0.9921569 ,\n",
       "        0.9921569 , 0.8117648 , 0.9921569 , 0.9215687 , 0.7803922 ,\n",
       "        0.82745105, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.52156866, 0.18823531, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09411766, 0.21176472, 0.21176472, 0.03137255,\n",
       "        0.21176472, 0.13725491, 0.        , 0.04705883, 0.21176472,\n",
       "        0.21176472, 0.49411768, 0.7725491 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9686275 , 0.38823533, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.0627451 , 0.46274513, 0.9450981 , 0.9921569 ,\n",
       "        0.97647065, 0.17254902, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30980393, 0.98823535, 0.9921569 , 0.85098046,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.7960785 , 0.9921569 , 0.9921569 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09411766, 0.09019608,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07450981, 0.6313726 , 0.9921569 , 0.9921569 ,\n",
       "        0.9490197 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49803925, 0.95294124, 0.94117653, 0.6784314 , 0.6784314 ,\n",
       "        0.6784314 , 0.6784314 , 0.47450984, 0.25882354, 0.05490196,\n",
       "        0.02352941, 0.25882354, 0.25882354, 0.6627451 , 0.8941177 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.28235295, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.54901963, 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.86274517, 0.8431373 , 0.9921569 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.94117653,\n",
       "        0.47450984, 0.02745098, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.01960784, 0.27450982, 0.4431373 ,\n",
       "        0.46274513, 0.86666673, 0.86666673, 0.86666673, 0.8941177 ,\n",
       "        0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.8705883 ,\n",
       "        0.86666673, 0.50980395, 0.20784315, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0627451 , 0.29411766, 0.29411766,\n",
       "        0.29411766, 0.29411766, 0.01176471, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape,x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将它绘制出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23d92fe7828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape([28,28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始回归\n",
    "这一节我们非常粗暴的忽略图像相邻像素之间的关联，把28\\*28的图像进行展开，得到一个784维的向量，然后把这个向量当成输入，并且不使用隐藏层，直接将输入层和输出层运用softmax分类器进行连接，得到预测的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025827 0.102\n",
      "0.5355226 0.892\n",
      "0.48929983 0.89\n",
      "0.4373034 0.874\n",
      "0.35466945 0.9\n",
      "0.3984976 0.902\n",
      "0.3870199 0.892\n",
      "0.37214842 0.906\n",
      "0.28934312 0.92\n",
      "0.32017913 0.914\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x_placeholder = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y_placeholder = tf.placeholder(tf.float32,shape=[None,10])\n",
    "# model\n",
    "with tf.variable_scope('network'):\n",
    "    logits = slim.fully_connected(x_placeholder,\n",
    "                                  10,\n",
    "                                  activation_fn=None,\n",
    "                                  weights_initializer=tf.zeros_initializer,\n",
    "                                  biases_initializer=tf.zeros_initializer)\n",
    "    y_p = tf.nn.softmax(logits)\n",
    "loss = slim.losses.softmax_cross_entropy(logits,y_placeholder)\n",
    "correct_prediction = tf.equal(tf.argmax(y_p,1),\n",
    "                              tf.argmax(y_placeholder,1))\n",
    "correct_prediction2 = tf.cast(correct_prediction,'float')\n",
    "accurrency = tf.reduce_mean(correct_prediction2)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss,var_list=tf.get_collection('trainable_variables'))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        if i%1000==0:\n",
    "            x_test,y_test = mnist.test.next_batch(500)\n",
    "            _loss,_accurrency = sess.run([loss,accurrency],feed_dict={x_placeholder:x_test,y_placeholder:y_test})\n",
    "            print(_loss,_accurrency)\n",
    "            pass\n",
    "        x_train,y_train = mnist.train.next_batch(100)\n",
    "        sess.run(train,feed_dict={x_placeholder:x_train,y_placeholder:y_train})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "可以看到训练的准确率达到了91%，也就是说，即使完全忽略像素之间的临近关心这一重要信息，我们仍可以获取到相当一部分信息来进行预测，不过在后面的学习中，我们将运用CNN卷积神经网络，进一步提升模型的准确率，最终，我们将能够得到一个准确率高达99%的模型！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
